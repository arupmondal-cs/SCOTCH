{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('3.8.0': pyenv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "64b110b1fa11b3e9996ddec44beebf006d6b16e6d401aed8c8757b566b81f52b"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL0CEEAbi0as"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import fashion_mnist as fmnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVB3_nv8swyt"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy import dstack \n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPI2dHOtrkml"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHqWCUqp9Gc2"
      },
      "source": [
        "#FedAvg using MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3W--962kVpS"
      },
      "source": [
        "### For N clients FedAvG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjbY9Mqn9Qs5"
      },
      "source": [
        "def avgWeights(scaledWeights):\n",
        "    avg = list()\n",
        "    for weight_list_tuple in zip(*scaledWeights):\n",
        "        layer_mean = tf.math.reduce_sum(weight_list_tuple, axis=0)\n",
        "        avg.append(layer_mean)\n",
        "    return avg\n",
        "\n",
        "def FedAvg(models):  \n",
        "    scaledWeights = []\n",
        "    for m in models:\n",
        "        scaledWeights.append(getScaledWeight(m, FLAccuracyDF.loc[m]['Weightage']))\n",
        "    avgWeight = avgWeights(scaledWeights)\n",
        "    return avgWeight\n",
        "\n",
        "def define_mod2(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=input_shape, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  # Configure the model and start training\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAelalCOrj59",
        "outputId": "72f62997-66c4-4cc7-ffdc-56951bdd9ae7"
      },
      "source": [
        "import numpy as np\n",
        "feature_vector_length = 784\n",
        "# Set the input shape\n",
        "input_shape = (feature_vector_length,)\n",
        "print(f'Feature shape: {input_shape}')\n",
        "\n",
        "# Load the data\n",
        "def load_dataset2(n_clients=3,permute=False):\n",
        "\n",
        "  client_datasets = {} # defining local datasets for each client\n",
        "\n",
        "  (X_train, Y_train), (X_test, Y_test) = fmnist.load_data()\n",
        "\n",
        " \n",
        "  X_train = X_train.reshape(X_train.shape[0], feature_vector_length)\n",
        "  X_test = X_test.reshape(X_test.shape[0], feature_vector_length)\n",
        "\n",
        "  if permute==True:\n",
        "    permutation_indexes = np.random.permutation(len(X_train))\n",
        "    X_train  = X_train[permutation_indexes]\n",
        "    Y_train = Y_train[permutation_indexes]\n",
        "\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_train /= 255\n",
        "  X_test /= 255\n",
        "\n",
        "  # Convert target classes to categorical ones\n",
        "  Y_train = to_categorical(Y_train)\n",
        "  Y_test = to_categorical(Y_test)\n",
        "\n",
        "  for i in range(n_clients):\n",
        "    client_datasets[i] = [X_train[i*(len(X_train)//n_clients):i*(len(X_train)//n_clients)+(len(X_train)//n_clients)],Y_train[i*(len(Y_train)//n_clients):i*(len(Y_train)//n_clients)+(len(Y_train)//n_clients)]]\n",
        "\n",
        "\n",
        "  return client_datasets  \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature shape: (784,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pngP_86SmNq8"
      },
      "source": [
        "def load_dataset3(n_clients=3,permute=False):\n",
        "\n",
        "  client_datasets = {} # defining local datasets for each client\n",
        "\n",
        "  (X_train, Y_train), (X_test, Y_test) = fmnist.load_data()\n",
        "\n",
        " \n",
        "  X_train = X_train.reshape(X_train.shape[0], feature_vector_length)\n",
        "  X_test = X_test.reshape(X_test.shape[0], feature_vector_length)\n",
        "\n",
        "  if permute==True:\n",
        "    permutation_indexes = np.random.permutation(len(X_train)//n_clients)\n",
        "    X_train  = X_train[permutation_indexes]\n",
        "    Y_train = Y_train[permutation_indexes]\n",
        "\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_train /= 255\n",
        "  X_test /= 255\n",
        "\n",
        "  # Convert target classes to categorical ones\n",
        "  Y_train = to_categorical(Y_train)\n",
        "  Y_test = to_categorical(Y_test)\n",
        "\n",
        "  return X_train,X_test,Y_train,Y_test\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPTGGhbjU5sA"
      },
      "source": [
        "def testing():\n",
        "\n",
        "  (_, _), (X_test, Y_test) = fmnist.load_data() \n",
        "  X_test = X_test.reshape(X_test.shape[0], feature_vector_length)\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_test /= 255\n",
        "  # Convert target classes to categorical ones\n",
        "  Y_test = to_categorical(Y_test)\n",
        "  return X_test,Y_test  \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXRRSFFmyEis"
      },
      "source": [
        "\n",
        "  \n",
        "#------------------------------------------------------------------------------\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def f_to_i(x,scale = 1<<32):\n",
        "  # print(f\" x : {x}\")\n",
        "\t # embed float value onto the integer ring\n",
        "  if x < 0:\n",
        "    if pow(2,64) - abs(x)*(scale) > (pow(2,64) - 1):\n",
        "      # print(pow(2,64) - abs(x)*(scale))\n",
        "      return np.uint64(0)\n",
        "    x = pow(2,64) - np.uint64(abs(x)*(scale))\n",
        "   \n",
        "  else:\n",
        "    x = np.uint64(scale*x)\n",
        "  \n",
        "  return np.uint64(x)\n",
        "\n",
        "\t\t\t\t\n",
        "\n",
        "\n",
        "def i_to_f(x,scale = 1<<32):\n",
        "  l=64\n",
        "  t = x > ( pow(2,(l-1)) -1 )\n",
        "  if t:\n",
        "    x = pow(2,l) - x\n",
        "    y = np.uint64(x)\n",
        "    y = np.float32(y*(-1))/scale\n",
        "    # y = np.array(y,dtype=np.float64)/scale\n",
        "  else:\n",
        "    y = np.float32(np.uint64(x))/scale\n",
        "    # y = np.array(y,dtype=np.float64)/scale\n",
        "\n",
        "  return y\n",
        "\n",
        "\n",
        "f_to_i_v = np.vectorize(f_to_i)\n",
        "i_to_f_v = np.vectorize(i_to_f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCj4liAFhSPi"
      },
      "source": [
        "\n",
        "def fed_avg_pipe(N_clients=10,num_of_iterations=3,num_servers=3):\n",
        "   \n",
        "  client_datasets = load_dataset2(N_clients,permute=True)\n",
        "  LD = len(client_datasets[0][0])//num_of_iterations\n",
        "\n",
        "  X_test,Y_test = testing()\n",
        "  avg_wts=0\n",
        "  for iteration in range(num_of_iterations):\n",
        "\n",
        "    list_of_weights = []\n",
        "    for j in range(N_clients):\n",
        "      if iteration==0:\n",
        "        model_c = define_mod2(input_shape)\n",
        "      else:\n",
        "        model_c = define_mod2(input_shape)\n",
        "        model_c.set_weights(avg_wts)\n",
        "\n",
        "\n",
        "      X_train,Y_train = client_datasets[j][0][(iteration*LD) :(iteration*LD)+LD],client_datasets[j][1][(iteration*LD) :(iteration*LD)+LD]\n",
        "      \n",
        "      model_c.fit(X_train, Y_train, epochs=4, batch_size=100, verbose=1, validation_split=0.1)\n",
        "\n",
        "      client_models[j]= model_c\n",
        "      W_c= model_c.get_weights()\n",
        "      list_of_weights.append(W_c)\n",
        "      \n",
        "    ################## Simulating Secret Sharing Framework Setting ####################################\n",
        "\n",
        "\n",
        "    final_weights=[None]*len(list_of_weights[0])\n",
        "    all_servers=[{}]*num_servers\n",
        "    for m in range(N_clients):\n",
        "      layer_dict,layer_shape,shares_dict={},{},{}\n",
        "      data=list_of_weights[m]\n",
        "      no_of_layers=len(data)\n",
        "      for i in range(len(data)):\n",
        "          layer_dict[i]=data[i]\n",
        "          layer_shape[i]=data[i].shape\n",
        "          \n",
        "      for i in range(no_of_layers):\n",
        "          shares_dict[i]=np.random.randint(1000,size=(num_servers,)+layer_shape[i],dtype=np.uint64)\n",
        "          x = f_to_i_v(layer_dict[i])\n",
        "          for k in range(0,num_servers-1):\n",
        "              shares_dict[i][k]=np.random.randint(1000,size=layer_shape[i],dtype=np.uint64)\n",
        "              x = x - shares_dict[i][k]\n",
        "          shares_dict[i][num_servers-1] = x\n",
        "                              \n",
        "      for i in range(num_servers):\n",
        "        if m==0:\n",
        "          for j in range(len(shares_dict)):\n",
        "            shape=shares_dict[j][0].shape\n",
        "            all_servers[i][j]=np.random.random_sample((N_clients,)+shape)\n",
        "            all_servers[i][j][m]=shares_dict[j][0] \n",
        "        else:\n",
        "          for j in range(len(shares_dict)):\n",
        "            all_servers[i][j][m]=shares_dict[j][i]\n",
        "\n",
        "\n",
        "    for i in range(num_servers):\n",
        "      for j in range(len(all_servers[0])):\n",
        "        all_servers[i][j] = f_to_i_v(i_to_f_v(all_servers[i][j])/np.float32(N_clients))\n",
        "       \n",
        "    for i in range(num_servers):\n",
        "      for j in range(len(all_servers[0])):\n",
        "        for k in range(N_clients):\n",
        "          if i==0 and k==0:\n",
        "            final_weights[j]=all_servers[i][j][k]\n",
        "          else:\n",
        "            final_weights[j]=final_weights[j]+all_servers[i][j][k]\n",
        "\n",
        "    for j in range(len(final_weights)):\n",
        "      final_weights[j]=i_to_f_v(final_weights[j])\n",
        "    avg_wts=final_weights\n",
        "    avg_model=define_mod2(input_shape)\n",
        "    avg_model.set_weights(avg_wts)\n",
        "################## Simulating Secret Sharing Framework Setting ####################################\n",
        "\n",
        "  test_results = avg_model.evaluate(X_test, Y_test, verbose=1)\n",
        "  return test_results[1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0e6rr0MiTzx"
      },
      "source": [
        "test_accuracies = []\n",
        "for y in range(4,5,1):\n",
        "  for q in range(2,5,1):\n",
        "    res = fed_avg_pipe(N_clients=q,num_of_iterations=y,num_servers=3)\n",
        "    test_accuracies.append(res)\n",
        "    #print(f\" {q} :  {res}\")\n",
        "  print(f\"\\n\\n\\n With {y} iterations the test_acc is {test_accuracies}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz5EUlSV_GFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b61d82e1-65d0-4518-b765-b7cbb951c0d7"
      },
      "source": [
        "print(test_accuracies)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8240000009536743, 0.6949999928474426, 0.4869999885559082]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}